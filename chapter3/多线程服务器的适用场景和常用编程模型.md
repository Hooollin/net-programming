# 多线程服务器的使用场景和常用编程模型

## 进程与线程
本书的进程指的是Linux操作系统通过fork()系统调用产生的那个东西，是比较重量级的对象。  

可以把进程比作一个人，每个人都有memory，人与人之间通过谈话（消息传递）来交流，可以面谈（同一个服务器），也可以在电话里谈（不同的服务器，网络通信）。面谈可以立即知道对方是否还或者（crash, SIGCHLD），而电话只可以通过周期性的心跳去判断对方是否还或者。  

线程在1993年以后流行起来，在1995年，POSIX threads标准确立。  

线程的特点是共享地址空间，从而可以高效的共享数据。  

## 单线程服务器的常用模型
高性能网络程序中，使用的最为广泛的要数“non-blocking IO + IO multiplexing”，称为Reactor模式，使用这种服务器的有：
- lighttpd，单线程服务器。
- libevent，libev。
- ACE，Poco C++ libraries。
- Java NIO，包括Apache Mina和Netty。
- POE。
- Twisted。

在“non-blocking IO + IO multiplexing”这种模型中，程序的基本结构是一个事件循环（event loop），以事件驱动（event-driven）和事件回调的方式实现业务逻辑：

```C++
while(!done){
    int timeout_ms = max(1000, getNextTimedCallback());
    int retval = ::poll(fds, nfds, timeout_ms);
    if(retval < 0){
        处理错误，或掉用户的error handler
    }else{
        处理到期的timers，回调用户的timer handler
            if(retval > 0){
                处理IO事件，回调用户的IO event handler
            }
    }
}
```
select和poll有伸缩性方面的不足，Linux下可替换为epoll，其他操作系统中也有对应的高性能替代品。  

## 多线程服务器的常用编程模型
- 为每个请求创建一个线程，使用阻塞式IO操作。
- 使用线程池，同样使用阻塞式IO操作，提高了部分性能。
- 使用non-blocking IO + IO multiplexing。
- Leader/Follower等高级模式。

默认情况下，作者更青睐第三种的模式来编写多线程C++网络服务程序。

### one loop per thread
程序里的每个IO线程有一个event loop（Reactor），用户处理读写和定时事件（周期或单次），代码框架如上。

> One loop per thread is usually a good model. Doing this is almost never wrong, sometimes a better-performance model exists, but it is always a good start. 

这种方式的优点是：
- 线程数基本固定，可以在程序启动的时候设置，不会频繁的创建与销毁。
- 可以很方便的在线程间调配负载。
- IO事件发生的线程是固定的，同一个TCP连接不必考虑事件并发。

Event loop代表了线程的主循环，需要让哪个线程干活，就把timer或IO channel注册到哪个线程的Loop里即可。
对实时性有要求的connection可以单独用一个线程；数据量大的connection可以独占一个线程，并且把处理任务分摊到另外几个计算线程中（线程池）；辅助性的connections可以共享一个线程。  

对于non-trivial的服务端程序，一般会采用non-blocking IO + IO multiplexing，每个connection都会注册到某个event loop上，程序中有多个event loop，每个线程至多有一个event loop。

### 线程池
如果对于没有IO而光有计算任务的线程，使用event loop比较浪费，作者提出一个补充方案，使用blocking queue实现的任务队列（TaskQueue）：  
```C++
typedef function<void()> Functor;
BlockingQueue<Functor> taskQueue;

void workerThread(){
  while(running){     //running是全局标志
    Functor task = taskQueue.take();
    task();
  }
}

// 启动并发数为N的线程
int N = num_of_cumputing_threads;
for(int i = 0; i < N; ++i){
  create_thread(&workerThread);
}


// 使用
Foo foo;
fucntion<void()> task = bind(&Foo::calc, &foo);
taskQueue.post(task);
```

### 推荐模式
作者推荐的C++多线程服务端编程模式为：one loop per thread + thread pool.
- event loop（IO loop）用作IO multiplexing，配合non-blocking IO和定时器。
- thread pool用来做计算，任务队列或生产者消费者队列。

以这种方式写服务器程序，需要一个优质的基于Reactor模式的网络库来支撑，所以有了muduo。  

### 进程间通信只用TCP
Linux下进程间通信方式有：匿名管道（pipe）、具名管道（FIFO）、POSIX消息队列、共享内存、信号、*Sockets*。  
作者提出首选Sockets（TCP）。好处在于：可以跨主机、具有伸缩性。  

编程上，TCP sockets和pipe都是操作文件描述符，用来收发字节流。不过TCP是双向的，较为方便。  

TCP port由一个进程独占，且操作系统会自动回收。即使程序意外退出，也不会给操作系统留下垃圾。同时独占也防止了程序重复启动。  

两个进程通过TCP通信，如果一个崩溃了，操作系统会关闭连接，另一个进程几乎立刻就能感知到，可以快速failover。不过应用层的心跳也是必不可少的。  

### 分布式系统中使用TCP长连接通信
分布式系统的软件设计和功能一般是是以“进程”为单位的。宏观上看，一个分布式系统是由多个运行在多台机器上的多个进程组成的，进程之间采用TCP长连接通信。  
作者提倡的多进程，并不是说把整个系统放到一个进程里实现，而是指功能划分之后，在实现每一类服务进程时，在必要时可以借助多线程来提高性能。对整个分布式系统而言，要能做到scale out，享受增加机器带来的好处。  

## 多线程服务器的适用场合
开发服务端程序的一个基本任务是处理并发连接，现在服务端网络编程处理并发连接主要由两种方式：
- “线程”创建廉价时，一台机器上可以创建高于CP数目的“线程”。如果一个线程只处理一个TCP连接，通常使用阻塞IO。这里的线程与操作系统的线程不是一回事，由语言的runtime自行调度。
- 当线程很宝贵时，一台机器上只能创建于CPU数目相当的线程。这时一个线程要处理多个TCP连接上的IO。通常使用非阻塞的IO和IO multiplexing。这里是原生线程，能被操作系统的任务调度器看见。

在Linux下使用native语言编写用户态高性能网络程序最成熟的模式是上述的第二种。  

考虑一台四核的普通机器，如果要在这样一个多核机器上提供一种服务或执行一个任务，可用的模式由：
1. 运行一个单线程的进程；
2. 运行一个多线程的进程；
3. 运行多个单线程的进程；
4. 运行多个多线程的进程。

对这四种模式的简单总结：
- 模式1是不可伸缩的，不能发挥多核机器的计算能力。  
- 模式3是目前工人的主流模式，有以下两种子模式：
  - 简单的把模式1中的进程运行多份
  - 如果必须绑定到一个TCP port的话，主进程+worker进程
- 模式2是被很多人鄙视的，认为多线程的程序难写，而且与模式3相比并没有什么优势。
- 模式4更是被万人唾弃，没有结合2与3的优点，反而汇聚了二者的缺点。 

作者提出了一个问题：什么时候一个服务器程序应该是多线程的？从功能上说，多线程能做到的，单线程肯定可以做到。从性能上说，无论是IO bound还是CPU bound的服务，多线程好像都没有什么优势。  

> As a rough rule of thumb, use the simplest tool that will get the job done.

具体场景分析：
> 如果使用速率为50MB/s的数据压缩库、在进程创建销毁的开销是800us、线程创建销毁开销是50us的前提下（1：16，与我测试结果相同）。考虑如何执行压缩任务：
- 如果偶尔压缩1GB的文件，预计运行时间是20s，那么起一个进程去做这个事情是合理的。
- 如果要经常压缩500kB的文本呢数据，预计运行时间是10ms，每次都起进程似乎有点浪费了，可以每次都单独起一个线程去做。
- 如果要频繁压缩10kB的文本数据，预计运行时间是200us，每次起线程似乎也很浪费，不如直接在当前线程搞定。也可以起一个线程池。  

由此可见，多线程并不是任何情况都合适。引出什么时候适合使用单线程，多线程的话题。

### 必须使用单线程的场合
- 程序可能会fork；
- 限制程序的CPU占用率。

只有单线程程序能fork。一个设计为可能调用fork(2)的程序必须是单线程的。多线程程序不是不能调用fork，而是这么做会遇到很多麻烦。一个程序fork后一般有两种行为：
- 立刻执行exec，变身为另一个程序，如shell以及看门狗进程。
- 不调用exe，继续运行当前程序。要么通过共享的文件描述符与父进程通信，协同完成任务；要么接过父进程传来的文件描述符，独立完成工作。

### 适用多线程程序的场景
作者认为多线程适用场景是：提高响应速度，让IO和“计算”相互重叠，降低延迟。多线程不能提高绝对性能，但能提高平均响应性能。  
一个程序要做成多线程的，需要满足：
- 有多个CPU可用。
- 线程之间有共享数据。
- 共享的数据是可以被修改的，而不是静态的常量表。
- 提供非均质的服务。时间的响应有优先级差异，可以用专门的线程来处理优先级高的事件，防止优先级反转。  
- latency和throughput同样重要。
- 采用异步操作。如logging。无论是忘磁盘写log file或者是往log server发送消息都不应该阻塞critical path。
- 能scale up。
- 具有可预测的性能。
- 有效划分责任与功能，让每个线程的逻辑比较简单，任务单一，便于编码。

适用于多线程的例子如下：
> 假设要管理一个Linux服务器集群，这个集群中有八个计算节点，一个控制节点，机器的配置都是一样的，双路四核CPU。现在需要编写一个简单的集群管理软件，这个软件主要由三部分组成：
> 1. 运行在控制节点上的master，这个程序件事并控制整个集群的状态。
> 2. 运行在每个计算节点上的slave，负责启动和终止job。
> 3. 供用户使用的client命令行工具，用户提交job。

slave是“看门狗进程”，它会启动别的job进程，因此必须是个单线程程序。另外它不该占用太多CPU资源，这也特别适合单线程模型。  
master应该是个一个多线程的进程的程序：
- 它独占一台八核的机器，如果用单线程的模型，等于浪费了87.5%的CPU资源。
- 整个集群的状态应该能完全放在内存中，并且这些状态是共享并可以改变的。
- master的主要性能指标不是throughput，而是latency，需要尽快响应各种事件。 
- master监控的事件有优先级区别，一个程序正常运行结束和异常崩溃的处理优先级不同，如果采用单线程模型，可能会出现优先级反转的问题。  
- 假设master和每个slave之间用一个TCP链接，那么master采用2个或4个IO线程来处理8个TCP链接能有效降低延迟。
- master需要异步往本地硬盘写log，需要有写log的IO线程。
- master可能要读写数据库，数据库连接这个第三方library可能有自己的线程，并回调master的代码。
- master要服务于多个client，用多线程也能降低客户端响应时间。
- master还可以提供一个monitor接口，用来广播集群的状态，这样用户不用主动polling。
- master一共开了十个线程。虽然线程的数量略多于核心数量，但是这些线程很多时候都是空闲的，可以依赖OS的进程调度来保证可控的延迟。


#### 线程的分类
一个多线程服务程序中的线程大致可分为3类：
- IO线程。这些线程的主循环是IO multiplexing。阻塞等在select/poll/epoll_wait系统调用上。
- 计算线程。这类线程的主循环是blocking queue，阻塞地等在condition variable上。这种线程通常不涉及IO，一般要避免任何阻塞操作。
- 第三方库所使用的线程，比如logging等。

服务器程序一般不会频繁地启动和终止线程。