# 线程同步精要
并发编程的两种基本模型：
- message passing
- shared memory  

分布式系统中只能采用messaging passing这一种并行编程的模型。  
单机上，如果照搬分布式系统中的并发模型，更容易保证程序的正确性。shared memory仍作为一种手段，以备不时之需。  

线程同步的四项原则（作者总结？）：
- 最低限度降低共享对象，减少需要同步的场合。
- 使用高级的并发编程构建，包括TaskQueue、Producer-Consumer Queue、CountDountLatch等。
- 不得已要使用底层同步原语时，使用非递归的互斥器（不可重入的锁）和条件变量，慎用读写锁，不用信号量。
- 除了使用atomic整数之外，不要编写lock-free代码。不用内核级的同步原语，不凭空猜测性能。

## mutex
保护critical section。单独使用mutex时，主要是为了保护共享数据。作者提出的原则如下：
- RAII包装Mutex。
- 使用非递归的mutex。
- 不手工调用lock和unlock。
- 思考调用栈上已持有的锁，防止加锁顺序不对导致死锁。

次要原则：
- 不使用跨进程的mutex，进程通信只通过TCP socket。
- 加锁、解锁在同一个线程。（RAII自动保证）

### 只使用不可重入的mutex
可重入锁可能带来难以排查的Bug。

```C++
mutex mu;
std::vector<Foo> foos;

void post(const Foo& f){
    std::lock_guard<mutex> lg;
    foos.push_back(f);
}

void traverse(){
    std::lock_guard<mutex> lg;
    for(auto it = foos.begin(); it != foos.end(); ++it){
        it->doit();
    }
}
```
大多数时间这段代码都不会出错。然而一旦`doit()`中调用了post，会出现意想不到的结果：
- mutex是不可重入的，死锁了。
- mutex是可重入的，迭代器可能失效。（内存重新分配）


## 条件变量
mutex是加锁原语，用来排他性地访问数据，但它不是等待原语。  
如果需要等待某个条件成立，我们需要使用条件变量（condition variable, \<condition\_variable\>）。  
学名叫管程（有这个说法吗？），包括wait()、notify()、notifyAll()三个基本操作。  

条件变量wait的用法：
- 必须和mutex一起使用，布尔表达式的读写受此mutex保护。
- mutex在已上锁的情况下才能使用wait()。
- 把判断布尔条件和wait()放到循环里面。

```C++
// a simple blocking queue
mutex mu;
condition_variable cv;
deque<int> queue;

int dequeue(){
    lock_guard<mutex> lg(mu);
    while(q.empty()){
        cv.wait(mu, [&queue]() -> bool{
                return !q.empty();
                });
    }
    assert(!q.empty());
    int top = queue.front();
    q.pop_front();
    return top;
}

void enqueue(int x){
    lock_guard<mutex> lg(mu);
    q.push_back(x);
    cv.notify_one();
}
```
条件变量是非常底层的同步原语，很少直接使用（应用层应该是很少直接使用吧，表示怀疑）。一般都是直接用它实现的高层同步措施，BlockingQueue、CountDownLatch。  

CountDownLatch是一种常用且易用的同步手段，用途在于：
- 主线程发起多个子线程，在子线程完成一定的初始化任务后，主线程才继续执行。（类似于Barrier）
- 主线程发起多个子线程，子线程都等待主线程，主线程完成其他任务后通知所有子线程开始执行。（起跑命令）

## 不要使用读写锁和信号量
读写锁明确区分了读写两种行为。 

共享数据频繁读而很少写，是否就需要使用读写锁来保护共享状态呢？不见得正确：
- 正确性上来说，在只有读锁的程序里修改共享数据是很严重的错误。
- 性能方面来说。读写锁不见得比普通的mutex高效。读写锁需要修改当前reader的数量。如果临界区很小，锁竞争不激烈，mutex往往会更快（不需要加入到等待队列中）。
- 通常reader lock是可重入的，writer lock是不可重入的。为了防止writer饥饿，writer lock通常会阻塞后来的reader lock，因此reader lock在重入的时候可能会死锁（没想明白）。

## 线程安全的Singleton实现
现在可以通过Magic Static实现线程安全的Singleton方法了。
```C++
class Singleton{
    private:
        Singleton() = default;
        ~Singleton() = default;
        Singleton(const Singleton&) = delete;
        Singleton(Singleton&&) = delete;
        Singleton& operator=(Singleton&) = delete;
        Singleton& operator=(Singleton&&) = delete;

    public:
        getInstance(){
            static Singleton instance;
            return instance;
        }
};

```
作者给出了一种利用pthread\_once的Singleton实现（C++11中应该是已经不会这样做了），不再赘述。

## sleep(3)不是同步原语
如果多线程的安全性和效率需要代码主动调用sleep保证，这显然是设计除了问题。正确的做法是通过select或condition\_variable等高层同步工具；用户态做轮询是低效的。

## 归纳
- 线程同步的四项原则。
- 多用RAII手法。

作者认为程序正确性比性能优化的优先级更高。效率并不是作者的主考虑点，作者提倡正确加锁而不是自己编写lock-free的算法，更不能想当然的自己发明同步设施。  
锁并不是程序变慢的原因，*锁争用*才是。  
在分布式系统中，多机伸缩性比单机性能更值得去优化。  

## copy on write
> Copy on write is a technique which allows you to update a data structure in a thread-safe way. The main advantage of copy on write is that reading threads get never blocked.

> 场景：多线程C++程序，有工作线程ThreaderWorker处理客户发过来的交易请求；另外有一个背景线程ThreadBackground，不定期更新程序内部的参考数据。这些线程都和一个hash表打交道，工作线程只读，背景线程读写，需要用到同步机制防止数据损坏。

系统要求工作线程的延迟尽可能小，可以容忍背景线程的延迟略大。背景线程对数据更新的次数屈指可数，可以容忍背景线程的延迟略大。  

最简单的同步方式是用读写锁：工作线程加读写锁，背景线程加写锁。读写锁的开销比普通的mutex更大，同时是写优先的，并且阻塞后面的读锁。
